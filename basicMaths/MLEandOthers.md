# MLEandOthers

### 贝叶斯公式

（条件概率：![img](https://bkimg.cdn.bcebos.com/formula/e30d3c07ebac8545498b8acac60f34e8.svg)）

**贝叶斯公式就是在描述，你有多大把握能相信一件证据**

$P(A|B) = \frac{P(B|A)P(A)}{P(B)}=\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\sim A)P(\sim A)}$即：证据可信度 = 证据出现事件发生/(证据出现事件发生+证据出现事件未发生)

突然发现：让$P(\sim A) $尽可能小，证据的说服力好像就会提高的样子，所以：**一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情**

例：发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。

### 似然函数

**概率是已知模型和参数，推数据。统计是已知数据，推模型和参数**

对于这个函数：x表示某一个具体的数据；θ表示模型的参数。

$P(x|\theta)$

+ 如果θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。

+ 如果x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。极大似然估计

### MLE最大似然估计

**利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值**

+ 求解问题：**模型已定，参数未知**

+ 例：正态分布![img](https://pic4.zhimg.com/80/v2-3013acd0b128bcc29cd4a4258f9bc6e7_720w.jpg)可利用此方法求解未知数**![[公式]](https://www.zhihu.com/equation?tex=%5Cmu)和![[公式]](https://www.zhihu.com/equation?tex=%5Csigma+)**

+ 前提：**所有的采样都是独立同分布的**

最大似然估计是求参数θ, 使似然函数P(x0|θ)最大。

例：拿硬币抛了10次，得到的数据（x0）是：反正正正正反正正正反。我们想求的正面概率θθ是模型参数，而抛硬币模型我们可以假设是 [二项分布](https://en.wikipedia.org/wiki/Binomial_distribution)。

似然函数：$f(x_0 ,\theta) = (1-\theta)\times\theta\times\theta\times\theta\times\theta\times(1-\theta)\times\theta\times\theta\times\theta\times(1-\theta) = \theta ^ 7(1 - \theta)^3 = f(\theta)$

函数取最大值时，得到估计的概率(0.7)

### 最大后验概率估计(MAP)

利用贝叶斯公式，检验估计的合理性。

后验概率： $P(\theta|x_0) = \frac{P(x_0|\theta)P(\theta)}{P(x_0)}=\frac{P(x_0|\theta)P(\theta)}{P(x_0|\theta)P(\theta) + P(x_0|\sim \theta)P(\sim \theta)}$      假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则P(x0)=n/1000。总之，这是一个可以由数据集得到的值）

使此公式取最大值时，不仅似然函数大，参数（$\theta$）出现的概率也得大，从而保障估计的准确性

对于投硬币的例子来看，我们（”先验地知道“）θ取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设P(θ)为均值0.5，方差0.1的高斯函数(正态分布)

一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）

### 总结

MAP就是多个作为因子的先验概率P(θ)。或者，也可以反过来，认为MLE是把先验概率P(θ)认为等于1，即认为θ是均匀分布。